{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import csv\n",
    "import re\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Row</th>\n",
       "      <th>Country</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>Income</th>\n",
       "      <th>Client_Ip</th>\n",
       "      <th>Date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Venezuela</td>\n",
       "      <td>Female</td>\n",
       "      <td>0-16</td>\n",
       "      <td>10k-20k</td>\n",
       "      <td>11.128.127.220</td>\n",
       "      <td>10/29/23 2:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Venezuela</td>\n",
       "      <td>Female</td>\n",
       "      <td>0-16</td>\n",
       "      <td>10k-20k</td>\n",
       "      <td>11.128.127.220</td>\n",
       "      <td>10/29/23 2:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Qatar</td>\n",
       "      <td>Male</td>\n",
       "      <td>46-55</td>\n",
       "      <td>20k-40k</td>\n",
       "      <td>96.212.217.245</td>\n",
       "      <td>10/29/23 9:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Qatar</td>\n",
       "      <td>Male</td>\n",
       "      <td>46-55</td>\n",
       "      <td>20k-40k</td>\n",
       "      <td>96.212.217.245</td>\n",
       "      <td>10/29/23 9:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Trinidad and Tobago</td>\n",
       "      <td>Male</td>\n",
       "      <td>17-25</td>\n",
       "      <td>60k-100k</td>\n",
       "      <td>149.121.160.201</td>\n",
       "      <td>10/29/23 16:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Row              Country  Gender    Age    Income        Client_Ip  \\\n",
       "0    1            Venezuela  Female   0-16   10k-20k   11.128.127.220   \n",
       "1    2            Venezuela  Female   0-16   10k-20k   11.128.127.220   \n",
       "2    3                Qatar    Male  46-55   20k-40k   96.212.217.245   \n",
       "3    4                Qatar    Male  46-55   20k-40k   96.212.217.245   \n",
       "4    5  Trinidad and Tobago    Male  17-25  60k-100k  149.121.160.201   \n",
       "\n",
       "             Date  \n",
       "0   10/29/23 2:00  \n",
       "1   10/29/23 2:00  \n",
       "2   10/29/23 9:00  \n",
       "3   10/29/23 9:00  \n",
       "4  10/29/23 16:00  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "requests = pd.read_csv('requests.csv')\n",
    "failures = pd.read_csv('failure.csv')\n",
    "requests.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60497, 7)\n"
     ]
    }
   ],
   "source": [
    "requests.dropna()\n",
    "failures.dropna()\n",
    "requests.drop(['Row'], axis=1, inplace=True)\n",
    "# append failure file to requests file\n",
    "files = failures['File']\n",
    "requests['File'] = files\n",
    "requests.drop_duplicates(inplace=True)\n",
    "print(requests.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9961157024793389\n",
      "Accuracy: 0.9961157024793389\n"
     ]
    }
   ],
   "source": [
    "countries = requests['Country']\n",
    "client_ip = requests['Client_Ip']\n",
    "\n",
    "def ip_to_number(ip):\n",
    "    parts = ip.split('.')\n",
    "    return int(parts[0]) * (256 * 256 * 256) + int(parts[1]) * (256 * 256) + int(parts[2]) * 256 + int(parts[3])\n",
    "\n",
    "client_ip = client_ip.apply(lambda x: int(''.join([i for i in x if i.isdigit()])))\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(client_ip, countries, test_size=0.2)\n",
    "\n",
    "# reshape to 2D array\n",
    "X_train = X_train.values.reshape(-1, 1)\n",
    "X_test = X_test.values.reshape(-1, 1)\n",
    "\n",
    "# Use a decision tree classifier\n",
    "clf = DecisionTreeClassifier()\n",
    "clf.fit(X_train, y_train)\n",
    "print(f\"Accuracy: {clf.score(X_test, y_test)}\")\n",
    "\n",
    "#import random forest classifier\n",
    "country_model = RandomForestClassifier(n_estimators=100, random_state=0)\n",
    "country_model.fit(X_train, y_train)\n",
    "print(f\"Accuracy: {country_model.score(X_test, y_test)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Income Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(38717, 3)\n",
      "      Country Gender Age\n",
      "45602     154      1   5\n",
      "66250      70      0   1\n",
      "28214      72      1   1\n",
      "90359     174      0   5\n",
      "59124     129      0   5\n",
      "...       ...    ...  ..\n",
      "41522     131      0   7\n",
      "20495     182      1   0\n",
      "39409     138      0   7\n",
      "35144     138      0   4\n",
      "47570     178      0   7\n",
      "\n",
      "[38717 rows x 3 columns]\n",
      "197\n",
      "Accuracy: 0.22520661157024793\n"
     ]
    }
   ],
   "source": [
    "features = requests.drop(['Date', 'Income', 'File', 'Client_Ip'], axis=1)\n",
    "income = requests['Income']\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "# use LabelEncoder to convert categorical data to numeric\n",
    "for col in features.columns:\n",
    "    if features[col].dtype == type(object):\n",
    "        le = LabelEncoder()\n",
    "        features[col] = le.fit_transform(features[col])\n",
    "for col in features.columns:\n",
    "    features[col] = features[col].astype('category')\n",
    "income = LabelEncoder().fit_transform(income)\n",
    "\n",
    "\n",
    "# features['Country'] = pd.Categorical(features['Country']).codes\n",
    "# features['Gender'] = pd.Categorical(features['Gender']).codes\n",
    "# features['Age'] = pd.Categorical(features['Age']).codes\n",
    "# income = pd.Categorical(income).codes\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(features, income, test_size=0.2)\n",
    "X_train, X_validation, y_train, y_validation = train_test_split(X_train, y_train, test_size=0.2)\n",
    "\n",
    "print(X_train.shape)\n",
    "print(X_train)\n",
    "print(len(X_train['Country'].unique()))\n",
    "#Use a decision tree classifier\n",
    "clf = DecisionTreeClassifier()\n",
    "clf.fit(X_train, y_train)\n",
    "print(f\"Accuracy: {clf.score(X_test, y_test)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(197, 50), (8, 4)]"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# categorical embedding for columns with more than 2 unique values\n",
    "embedded_cols = {n: len(col.cat.categories) for n, col in features.items() if len(col.cat.categories) > 2}\n",
    "embedded_cols_names = embedded_cols.keys()\n",
    "len(features.columns) - len(embedded_cols_names)\n",
    "\n",
    "# embedding sizes\n",
    "embedded_size = [(n_categories, min(50, (n_categories + 1) // 2)) for _, n_categories in embedded_cols.items()]\n",
    "embedded_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "import torchvision\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms, utils\n",
    "from torch import nn, optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CountriesDataset(Dataset):\n",
    "    def __init__(self, X, y, embedded_col_names):\n",
    "        X1 = X.copy()\n",
    "        self.X1 = X.loc[:, embedded_col_names].copy().values.astype(np.int64)\n",
    "        self.X2 = X.drop(columns=embedded_col_names).copy().values.astype(np.float32)\n",
    "        self.y = y\n",
    "    def __len__(self):\n",
    "        return len(self.y)\n",
    "    def __getitem__(self, idx):\n",
    "        return [self.X1[idx], self.X2[idx]], self.y[idx]\n",
    "train_ds = CountriesDataset(X_train, y_train, embedded_cols_names)\n",
    "valid_ds = CountriesDataset(X_validation, y_validation, embedded_cols_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CountriesOutcomeModel(nn.Module):\n",
    "    def __init__(self, embedded_size, n_cont):\n",
    "        super().__init__()\n",
    "        self.embeds = nn.ModuleList([nn.Embedding(categories, size) for categories, size in embedded_size])\n",
    "        n_emb = sum(e.embedding_dim for e in self.embeds)\n",
    "        self.n_emb, self.n_cont = n_emb, n_cont\n",
    "        self.lin1 = nn.Linear(self.n_emb + self.n_cont, 100)\n",
    "        self.lin2 = nn.Linear(100, 50)\n",
    "        self.lin3 = nn.Linear(50, 2)\n",
    "        self.bn1 = nn.BatchNorm1d(self.n_cont)\n",
    "        self.bn2 = nn.BatchNorm1d(100)\n",
    "        self.bn3 = nn.BatchNorm1d(50)\n",
    "        self.emb_drop = nn.Dropout(0.6)\n",
    "        self.drops = nn.Dropout(0.3)\n",
    "    def forward(self, x_cat, x_cont):\n",
    "        x = [e(x_cat[:, i]) for i, e in enumerate(self.embeds)]\n",
    "        x = torch.cat(x, 1)\n",
    "        x = self.emb_drop(x)\n",
    "        x2 = self.bn1(x_cont)\n",
    "        x = torch.cat([x, x2], 1)\n",
    "        x = F.relu(self.lin1(x))\n",
    "        x = self.drops(x)\n",
    "        x = self.bn2(x)\n",
    "        x = F.relu(self.lin2(x))\n",
    "        x = self.drops(x)\n",
    "        x = self.bn3(x)\n",
    "        x = self.lin3(x)\n",
    "        return x\n",
    "    \n",
    "model = CountriesOutcomeModel(embedded_size, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_optimzer(model, lr = 0.001, wd = 0.0):\n",
    "    parameters = filter(lambda p: p.requires_grad, model.parameters())\n",
    "    optimzer = torch.optim.Adam(parameters, lr=lr, weight_decay=wd)\n",
    "    return optimzer\n",
    "\n",
    "def train_model(model, optimizer, train_dl):\n",
    "    model.train()\n",
    "    total = 0\n",
    "    sum_loss = 0\n",
    "    for x, y in train_dl:\n",
    "        batch = y.shape[0]\n",
    "        output = model(x[0], x[1])\n",
    "        loss = F.cross_entropy(output, y)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total += batch\n",
    "        sum_loss += batch*(loss.item())\n",
    "    return sum_loss/total\n",
    "\n",
    "def val_loss(model, valid_dl):\n",
    "    model.eval()\n",
    "    total = 0\n",
    "    sum_loss = 0\n",
    "    correct = 0\n",
    "    for x1, x2, y in valid_dl:\n",
    "        current_batch_size = y.shape[0]\n",
    "        out = model(x1, x2)\n",
    "        loss = F.cross_entropy(out, y)\n",
    "        sum_loss += current_batch_size*(loss.item())\n",
    "        total += current_batch_size\n",
    "        pred = torch.max(out, 1)[1]\n",
    "        correct += (pred == y).float().sum().item()\n",
    "    print(\"valid loss %.3f and accuracy %.3f\" % (sum_loss/total, correct/total))\n",
    "    return sum_loss/total, correct/total\n",
    "\n",
    "\n",
    "batch_size = 1000\n",
    "train_dl = DataLoader(train_ds, batch_size=batch_size, shuffle=True)\n",
    "valid_dl = DataLoader(valid_ds, batch_size=batch_size)\n",
    "\n",
    "def train_loop(model, epochs, lr=0.01, wd=0.0):\n",
    "    optim = get_optimzer(model, lr = lr, wd = wd)\n",
    "    for i in range(epochs):\n",
    "        loss = train_model(model, optim, train_dl)\n",
    "        print(\"training loss %.3f\" % loss)\n",
    "        val_loss(model, valid_dl)\n",
    "train_loop(model, epochs=100, lr=0.01, wd=0.0001)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "605\n",
      "<__main__.Dataset object at 0x16800c950>\n"
     ]
    }
   ],
   "source": [
    "class Dataset(Dataset):\n",
    "    def __init__(self, X, y):\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return self.X[idx], self.y[idx]\n",
    "\n",
    "train_dataset = Dataset(X_train, y_train)\n",
    "val_dataset = Dataset(X_validation, y_validation)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=64, shuffle=True)\n",
    "\n",
    "print(len(train_loader))\n",
    "print(train_loader.dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.fc1 = nn.Linear(5, 100)\n",
    "        self.fc2 = nn.Linear(100, 100)\n",
    "        self.fc3 = nn.Linear(100, 2)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        return F.softmax(self.fc3(x), dim=1)\n",
    "\n",
    "model = Net()\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "epochs = 100 \n",
    "train_losses, val_losses = [], []\n",
    "elem1 = train_loader.dataset.X\n",
    "\n",
    "for e in range(epochs):\n",
    "    running_loss = 0\n",
    "    for X, y in train_loader:\n",
    "        optimizer.zero_grad() \n",
    "        output = model(X.float())\n",
    "        y = y.long()\n",
    "\n",
    "        loss = criterion(output, y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "    else:\n",
    "        val_loss = 0\n",
    "        accuracy = 0\n",
    "    \n",
    "        with torch.no_grad():\n",
    "            model.eval()\n",
    "            for X, y in val_loader:\n",
    "                output = model(X.float())\n",
    "                val_loss += criterion(output, y)\n",
    "                \n",
    "                top_p, top_class = output.topk(1, dim=1)\n",
    "                equals = top_class == y.view(*top_class.shape)\n",
    "                accuracy += torch.mean(equals.type(torch.FloatTensor))\n",
    "        \n",
    "        model.train()\n",
    "        \n",
    "        train_losses.append(running_loss/len(train_loader))\n",
    "        val_losses.append(val_loss/len(val_loader))\n",
    "        \n",
    "        print(\"Epoch: {}/{}.. \".format(e+1, epochs),\n",
    "             \"Training Loss: {:.3f}.. \".format(running_loss/len(train_loader)),\n",
    "             \"Validation Loss: {:.3f}.. \".format(val_loss/len(val_loader)),\n",
    "             \"Validation Accuracy: {:.3f}\".format(accuracy/len(val_loader)))\n",
    "\n",
    "plt.plot(train_losses, label='Training loss')\n",
    "plt.plot(val_losses, label='Validation loss')\n",
    "plt.legend(frameon=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
